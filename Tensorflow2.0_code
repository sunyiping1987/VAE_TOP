import  os
import  tensorflow as tf
import  numpy as np
from    tensorflow import keras
from    PIL import Image
from    matplotlib import pyplot as plt
import glob
import os

import pandas as pd
import numpy as np
import xlrd
import xlwt  # 引用写入的库
import xlsxwriter



tf.random.set_seed(22)
np.random.seed(22)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
assert tf.__version__.startswith('2.')


image_path = glob.glob(r'F:\SOFTWARE\Aticlefour\practise_delete_images123\del\*.png')

image_counts = len(image_path)
print(image_counts)

def load_preprosess_image(path):

    image = tf.io.read_file(path)
    image = tf.image.decode_png(image, channels=1)
    # image = tf.image.resize_with_crop_or_pad(image, 64, 64)
    image = tf.cast(image,tf.float32)
    image = (image/255.)
    return image

image_ds = tf.data.Dataset.from_tensor_slices(image_path)

AUTOTUNE = tf.data.experimental.AUTOTUNE

image_ds = image_ds.map(load_preprosess_image, num_parallel_calls=AUTOTUNE)

print(image_ds)

image_ds = image_ds.shuffle(image_counts).batch(100)
print(image_ds)

dataset = image_ds.prefetch(AUTOTUNE)
print(dataset)

#
#
# (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
# x_train, x_test = x_train.astype(np.float32)/255., x_test.astype(np.float32)/255.
#
#
#
# # In[19]:
#
#
# print(x_train.shape, y_train.shape)
# print(x_test.shape, y_test.shape)
#

# image grid
new_im = Image.new('L', (1280, 1280))

image_size = 128*128
h_dim = 512
z_dim = 100
num_epochs = 500
batch_size = 100
learning_rate = 4e-4


class VAE(tf.keras.Model):

    def __init__(self):
        super(VAE, self).__init__()

        # # input => h
        # self.fc1 = keras.layers.Dense(h_dim)
        # # h => mu and variance
        # self.fc2 = keras.layers.Dense(z_dim)
        # self.fc3 = keras.layers.Dense(z_dim)
        #
        # # sampled z => h
        # self.fc4 = keras.layers.Dense(h_dim)
        # # h => image
        # self.fc5 = keras.layers.Dense(image_size)

        self.n_f = 32
        self.n_k = 4

        # input image is [-1, 64, 64, 1]
        self.conv1 = keras.layers.Conv2D(self.n_f, self.n_k, 2, 'same')  #[64 64 32]
        self.bn1 = keras.layers.BatchNormalization()
        self.conv2 = keras.layers.Conv2D(self.n_f * 2, self.n_k, 2, 'same')#[32 32 64]
        self.bn2 = keras.layers.BatchNormalization()
        self.conv3 = keras.layers.Conv2D(self.n_f * 4, self.n_k, 2, 'same')#[16 16 128]
        self.bn3 = keras.layers.BatchNormalization()
        self.flatten4 = keras.layers.Flatten()
        self.dense4 = keras.layers.Dense(z_dim)
        self.dense5 = keras.layers.Dense(z_dim)

        # decode
        self.n_f_f = 128
        self.n_k_k = 4

        # input z vector is [None, 20]
        self.dense6 = keras.layers.Dense(16 * 16 * self.n_f_f) #[16 16 128]
        self.conv2_2 = keras.layers.Conv2DTranspose(self.n_f_f // 2, self.n_k_k, 2, 'same')#[32 32 64]
        self.bn2_2 = keras.layers.BatchNormalization()
        self.conv3_3 = keras.layers.Conv2DTranspose(self.n_f_f // 4, self.n_k_k, 2, 'same')#[64 64 32]
        self.bn3_3 = keras.layers.BatchNormalization()
        self.conv4_4 = keras.layers.Conv2DTranspose(1, self.n_k_k, 2, 'same')#[128 128 1]
        self.bn4_4 = keras.layers.BatchNormalization()


    def encode(self, x):
        # h = tf.nn.relu(self.fc1(x))
        # # mu, log_variance
        # return self.fc2(h), self.fc3(h)

        h = self.conv1(x)
        h = tf.nn.leaky_relu(self.bn1(h))
        h = self.conv2(h)
        h = tf.nn.leaky_relu(self.bn2(h))
        h = self.conv3(h)
        h = tf.nn.leaky_relu(self.bn3(h))
        h = self.flatten4(h)

        # mu, log_variance
        return self.dense4(h), self.dense5(h)

    def reparameterize(self, mu, log_var):
        """
        reparametrize trick
        :param mu:
        :param log_var:
        :return:
        """
        std = tf.exp(log_var * 0.5)
        eps = tf.random.normal(std.shape)

        return mu + eps * std

    def decode_logits(self, z):
        # h = tf.nn.relu(self.fc4(z))
        # return self.fc5(h)

        h = tf.nn.leaky_relu(self.dense6(z))
        h = tf.reshape(h, [-1, 16, 16, 128])
        h = self.conv2_2(h)
        h = tf.nn.leaky_relu(self.bn2_2(h))
        h = self.conv3_3(h)
        h = tf.nn.leaky_relu(self.bn3_3(h))
        h = self.conv4_4(h)
        h = self.bn4_4(h)
        return h

    def decode(self, z):
        return tf.nn.sigmoid(self.decode_logits(z))

    def call(self, inputs, training=None, mask=None):
        # encoder
        mu, log_var = self.encode(inputs)
        # sample
        z = self.reparameterize(mu, log_var)
        # decode
        x_reconstructed_logits = self.decode_logits(z)

        return x_reconstructed_logits, mu, log_var


model = VAE()
# model.build(input_shape=(4, image_size))
model.build(input_shape=(4, 128, 128, 1))

model.summary()
optimizer = keras.optimizers.Adam(learning_rate)



#
# # we do not need label
# dataset = tf.data.Dataset.from_tensor_slices(x_train)
# dataset = dataset.shuffle(batch_size * 5).batch(batch_size)
#
# num_batches = x_train.shape[0] // batch_size

loss_total = []
loss_reconstructed = []

num_batches = image_counts // batch_size
for epoch in range(num_epochs):

    for step, x in enumerate(dataset):

        # x = tf.reshape(x, [-1, image_size])


        with tf.GradientTape() as tape:

            # Forward pass
            x_reconstruction_logits, mu, log_var = model(x)

            # Compute reconstruction loss and kl divergence
            # For KL divergence, see Appendix B in VAE paper or http://yunjey47.tistory.com/43
            # Scaled by `image_size` for each individual pixel.
            reconstruction_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=x, logits=x_reconstruction_logits)
            reconstruction_loss = tf.reduce_sum(reconstruction_loss) / batch_size
            # please refer to
            # https://stats.stackexchange.com/questions/7440/kl-divergence-between-two-univariate-gaussians
            kl_div = - 0.5 * tf.reduce_sum(1. + log_var - tf.square(mu) - tf.exp(log_var), axis=-1)
            kl_div = tf.reduce_mean(kl_div)

            # Backprop and optimize
            loss = tf.reduce_mean(reconstruction_loss) + kl_div

        gradients = tape.gradient(loss, model.trainable_variables)
        for g in gradients:
            tf.clip_by_norm(g, 15)
        optimizer.apply_gradients(zip(gradients, model.trainable_variables))

        loss_total.append(float(kl_div))
        loss_reconstructed.append(float(tf.reduce_mean(reconstruction_loss)))


        if (step + 1) % 5 == 0:
            print("Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}"
                  .format(epoch + 1, num_epochs, step + 1, num_batches, float(reconstruction_loss), float(kl_div)))




    # if epoch+1 >=2:
        # loss 保存KL_div
        if (step + 1) % 1 == 0:
            workbook1 = xlwt.Workbook()
            worksheet1 = workbook1.add_sheet("kl_div")  # 新建sheet
            row1, col1 = 0, 0

            # print('kl_div:', float(kl_div))

            stem1 = 0
            for item1, cost1 in enumerate(loss_total):
                # print('item1:', stem1, 'cost1', cost1)
                worksheet1.write(row1, col1, stem1)
                worksheet1.write(row1, col1 + 1, np.float(cost1))
                row1 += 1
                stem1 += 1

            workbook1.save(
                r'F:\SOFTWARE\Aticlefour\深度学习与TF-PPT和代码\深度学习与TF-PPT和代码\lesson22-VAE\loss_train\loss_KL_div.xlsx')  # 保存



        # loss 保存loss_reconstructed
        workbook2 = xlwt.Workbook()
        worksheet1 = workbook2.add_sheet("reconstructed_loss")  # 新建sheet
        row2, col2 = 0, 0

        # print('kl_div:', float(kl_div))

        stem2 = 0
        for item2, cost2 in enumerate(loss_reconstructed):
            # print('item1:', stem1, 'cost1', cost1)
            worksheet1.write(row2, col2, stem2)
            worksheet1.write(row2, col2 + 1, np.float(cost2))
            row2 += 1
            stem2 += 1

        workbook2.save(
            r'F:\SOFTWARE\Aticlefour\深度学习与TF-PPT和代码\深度学习与TF-PPT和代码\lesson22-VAE\loss_train\loss_reconstructed.xlsx')  # 保存






    # Generative model
    z = tf.random.normal((batch_size, z_dim))
    out = model.decode(z)  # decode with sigmoid
    out = tf.reshape(out, [-1, 128, 128]).numpy() * 255.
    out = out.astype(np.uint8)


    # since we can not find image_grid function from vesion 2.0
    # we do it by hand.
    index = 0
    for i in range(0, 1280, 128):
        for j in range(0, 1280, 128):
            im = out[index]
            im = Image.fromarray(im, mode='L')
            new_im.paste(im, (i, j))
            index += 1

    new_im.save('images/vae_sampled_epoch_%d.png' % (epoch + 1))
    plt.imshow(np.asarray(new_im))
    # plt.show()

    # Save the reconstructed images of last batch
    out_logits, _, _ = model(x[:batch_size // 2])
    out = tf.nn.sigmoid(out_logits)  # out is just the logits, use sigmoid
    # out = tf.reshape(out, [-1, 28, 28]).numpy() * 255
    out = tf.reshape(out, [-1, 128, 128]).numpy()

    x = tf.reshape(x[:batch_size // 2], [-1, 128, 128])

    x_concat = tf.concat([x, out], axis=0).numpy() * 255.
    x_concat = x_concat.astype(np.uint8)

    index = 0
    for i in range(0, 1280, 128):
        for j in range(0, 1280, 128):
            im = x_concat[index]
            im = Image.fromarray(im, mode='L')
            new_im.paste(im, (i, j))
            index += 1

    new_im.save('images/vae_reconstructed_epoch_%d.png' % (epoch + 1))
    plt.imshow(np.asarray(new_im))
    # plt.show()
    print('New images saved !')





# 保存model_VAE
model.save_weights(r'F:\SOFTWARE\Aticlefour\深度学习与TF-PPT和代码\深度学习与TF-PPT和代码\lesson22-VAE\model_VAE_weights\weights.ckpt')
print('saved weights.')
# del model_MLP
